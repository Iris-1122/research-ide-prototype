# 智研 Agent（Prototype）

> 面向人文社科研究者的 Research IDE + 工作流型 AI Agent  
> 通过结构化中间态（SDT）与强制人机协同断点（HITL），  
> 将研究中的“体力劳动”交给 AI，把关键决策权交还给人。

---

## 项目简介

**智研 Agent** 是一个面向人文社科研究场景的 AI Agent 原型。

它旨在将研究过程中高度重复、低创造性的环节（如检索、初筛、结构化整理）通过 Agent Workflow 完成，使研究者能够将精力集中于 AI 真正不可替代的思想判断、理论建构与方向性决策。

项目通过 **结构化中间态（SDT）** 与 **强制的人机协同断点（HITL）**，确保研究方向、论据选择与最终判断始终由用户掌控。
以 **Research IDE（集成式研究工作空间）** 为核心形态，而非聊天型工具，探索 AI 在严肃研究工作流中的合理位置。

---



## 界面预览（Screenshots）

🔗 在线演示：coming soon  
📌 核心能力：以 SDT（结构化中间态）+ HITL（强制断点）实现“可控、可追溯、可纠偏”的研究工作流

**流程概览：Research IDE → SDT → HITL → Synthesis（含 Evidence 映射）**

**1) SDT：候选文献结构化表格 + Evidence / Sources （证据与来源）面板**  
<img src="assets/02-sdt-table.png" width="900" />

**2) HITL：强制断点（确认后才进入综合生成）**  
<img src="assets/03-hitl-checkpoint.png" width="900" />

<details>
  <summary><b>更多截图（输入页 & 综合结果）</b></summary>

  <br/>

  **0) Research IDE（输入研究问题）**  
  <img src="assets/01-ide-home.png" width="900" />

  **3) Synthesis：研究脉络与选题 + Evidence 映射（可追溯）**  
  <img src="assets/04-synthesis-evidence.png" width="900" />

</details>



## 为什么要设计这款产品？

当前主流的 AI 学术工具，并未真正解决研究者的实际工作流程问题：

1. **研究流程被工具割裂** ：

     文献检索、AI 辅助整理、写作与查重分散在不同工具中，研究者需要在多个软件之间反复切换，效率低且体验割裂。

2. **AI 与 Agent 能力在科研场景未深度融合** ：

    任务型 Agent 能串流程，却缺乏研究判断且过程黑盒；大模型具备思考深度能力，却无法被纳入可控工作流，二者难以协同。

3. **黑箱输出导致成本与风险失控** ：

    一次性报告式生成过程不可见、不可叫停，方向错误时不仅浪费成本，也模糊了研究责任边界。

智研 Agent 正是针对上述问题，尝试用 **工作流 + 人机协同机制**，以 **Research IDE（集成式研究工作空间）** 为核心形态，重构 AI 在研究中的参与方式。

---

## 设计核心亮点：以人机协同（HITL）作为研究护栏

智研 Agent 并未采用“一跑到底”的 Agent 设计，而是引入 **Human-in-the-Loop（HITL）** 强制断点，将人类判断制度化地嵌入研究流程中。

在这一流程中，AI 被明确限制为「研究助理」角色，而非研究主体或作者；关键决策权被“机制化”地留给用户。

1. **HITL：把伦理边界写进产品机制** 智研不是“让 AI 写论文”，而是通过强制断点让 AI 在关键节点必须停下，等待人类确认，避免工具替人作出研究判断，降低学术不端风险。

2. **SDT：用结构化中间态拆开黑盒** 候选条目、论据与来源先以结构化表格呈现，用户能看到“AI 到底拿了什么材料”，而不是被一段总结文本直接覆盖研究过程。

3. **可叫停、可纠偏：降低试错成本，提升命中率** 工作流把过程显性化：偏题可以在早期就停下或调整，而不是等到最终长文生成才发现不对，再推倒重来。

---


## 研究工作流示意图

```mermaid
flowchart TD
  A[Research Topic / Research Question] --> B[SDT: Candidate Generation<br/>Structured Data Table]
  B --> C{HITL: Mandatory Checkpoint<br/>Human Selection & Confirmation}
  C -->|Confirm Selected Items| D[Synthesis: Research Threads<br/>Outline / Directions]
  D --> E[Evidence / Sources Panel<br/>Traceable Mapping]

  classDef box fill:#ffffff,stroke:#334155,stroke-width:1px;
  classDef checkpoint fill:#fff7ed,stroke:#f97316,stroke-width:2px;

  class A,B,D,E box
  class C checkpoint
```

---

## 当前已实现功能（Prototype）

- ✅ 本地前后端完整跑通（FastAPI + 前端原型）
- ✅ 研究流程闭环：**SDT → HITL → Synthesis**
- ✅ 候选文献以结构化表格（SDT）形式呈现
- ✅ 用户式勾选论据后，AI 才进入综合生成阶段（HITL 断点生效）
- ✅ Evidence / Sources 与生成内容保持对应关系（便于追溯与复盘）
- ✅ 支持真实大模型调用（模型可替换）

> 当前版本为 **单机原型（Local-first）**，重点验证流程合理性与协作机制，而非规模化能力。

---

## 技术选型说明

- **后端**：FastAPI  
- **前端**：HTML + 原生 JavaScript（原型阶段）  
- **模型层**：模型可替换（当前以通用大模型 API 为例）  
- **架构原则**：模型无关（Model-agnostic），流程优先于模型能力  

项目重点不在于“使用哪一个模型”，而在于 **如何编排模型参与研究流程**。

---

## 项目状态说明

⚠️ 本项目为 **研究型产品原型（Prototype）**：

- 未引入数据库持久化  
- 未实现多用户与权限系统  
- 未接入真实学术数据库（如 CNKI / Zotero 等）  
- 不以“可商用”或“完整 SaaS”作为当前目标  

**当前阶段目标：**

> 验证「结构化中间态（SDT）+ HITL 强制断点」  
> 是否能够显著提升研究型 AI 的可靠性、可控性与责任清晰度。

---


## 风险与边界（产品机制护栏）

智研 Agent 的目标不是“让 AI 写论文”，而是将 AI 限制在「研究助理」角色，并通过 SDT + HITL 把关键判断权制度化地交还给用户。

主要风险与对应机制如下：

- **幻觉与证据错配风险**：模型可能生成看似合理但并不来自证据的论断。  
  → 通过 SDT（结构化候选）与 Evidence 映射，要求“观点—来源”可追溯，并保留人工复核空间。

- **来源可靠性风险**：候选材料可能来自低质量或二手内容。  
  → 明确展示来源与可信度线索，允许用户删除/替换条目后再进入综合阶段。

- **学术不端与责任边界风险**：若把 AI 当“作者”，会模糊研究责任。  
  → HITL 强制断点要求用户确认“采用哪些论据/材料”，把责任边界写进交互机制。

- **提示注入与恶意内容风险**：来源文本可能包含诱导指令，导致模型偏离任务。  
  → 将来源作为“引用材料”而非“指令”，并在流程上隔离模型决策权。

- **隐私与合规风险**：研究问题、笔记可能包含敏感信息。  
  → 当前版本以 Local-first 原型为主；若未来云化将需要明确数据存储、日志、密钥管理与权限策略。

- **价值立场与偏见风险（社科场景尤甚）**：输出易受框架偏置影响。  
  → 用多视角候选与可见的选择过程替代单一路径黑箱生成，鼓励研究者主动比较与裁决。



---


## 环境配置与模型路由（可见降级）

智研 Agent 支持“模型路由 + 可见降级”，用于在不同网络/额度/可用性条件下保持工作流可用。

### 默认路径优先级
**Zhipu GLM → Gemini → Mock**

- 当智谱调用成功时，界面会显示：`本次生成：glm-4.5-air｜未降级`
- 当上游不可用（网络/额度/超时/鉴权失败等）时，会自动降级到下一模型，并在 UI 中标注“已降级”（或展示当前命中的模型）

### 环境变量（示例）

你可以在 `.env` 中配置不同提供方的 Key / Base URL（按需配置即可）：

- `ZHIPU_API_KEY`：智谱 Key（优先使用）
- `GEMINI_API_KEY`：Gemini Key（智谱失败时降级使用）
- `MODEL_NAME`：默认模型名（如 `glm-4.5-air`）
- `BASE_URL`：可选（当你使用兼容网关/代理时）

> 未配置任何真实模型 Key 时，系统将进入 **Mock** 模式，用示例数据演示 SDT → HITL → Synthesis 的完整机制闭环（用于展示流程与交互护栏，而非比拼模型能力）。



## 如何运行（本地）

```bash
# 安装依赖
pip install -r requirements.txt

# 配置环境变量
cp .env.example .env

# 启动后端
python server.py
```

---

## 下一步计划（Roadmap）

- [ ] 引入状态机机制（可暂停 / 可回溯的研究流程）
- [ ] 将 SDT 持久化，支持跨会话研究
- [ ] 前端升级为组件化框架（React / Vue）
- [ ] 探索文献导入能力（PDF / 文献管理工具）
- [ ] 写作编辑区（副驾驶式迭代，围绕“引用—论据—段落”联动）



## 声明

本项目用于探索 AI Agent 在学术研究中的合理边界，不用于替代人工写作或规避学术规范，研究结论与引用责任始终由用户承担。

